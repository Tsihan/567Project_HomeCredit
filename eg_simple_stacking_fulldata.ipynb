{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:46:56.945581Z",
     "start_time": "2024-04-08T21:46:56.255084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e27533f88ade988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:46:56.948761Z",
     "start_time": "2024-04-08T21:46:56.946422Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # implement here all desired dtypes for tables\n",
    "    # the following is just an example\n",
    "    for col in df.columns:\n",
    "        # last letter of column name will help you determine the type\n",
    "        if col[-1] in (\"P\", \"A\"):\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:  \n",
    "        if df[col].dtype.name in ['object', 'string']:\n",
    "            df[col] = df[col].astype(\"string\").astype('category')\n",
    "            current_categories = df[col].cat.categories\n",
    "            new_categories = current_categories.to_list() + [\"Unknown\"]\n",
    "            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n",
    "            df[col] = df[col].astype(new_dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d528121811f71d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:46:58.920442Z",
     "start_time": "2024-04-08T21:46:56.949272Z"
    }
   },
   "outputs": [],
   "source": [
    "train_basetable = pl.read_csv(\"train/train_base.csv\")\n",
    "train_static = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(\"train/train_static_0_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"train/train_static_0_1.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "train_static_cb = pl.read_csv(\"train/train_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "train_person_1 = pl.read_csv(\"train/train_person_1.csv\").pipe(set_table_dtypes) \n",
    "train_credit_bureau_b_2 = pl.read_csv(\"train/train_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140f038523f88e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:46:58.928945Z",
     "start_time": "2024-04-08T21:46:58.921129Z"
    }
   },
   "outputs": [],
   "source": [
    "test_basetable = pl.read_csv(\"test/test_base.csv\")\n",
    "test_static = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(\"test/test_static_0_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"test/test_static_0_1.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"test/test_static_0_2.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "test_static_cb = pl.read_csv(\"test/test_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "test_person_1 = pl.read_csv(\"test/test_person_1.csv\").pipe(set_table_dtypes) \n",
    "test_credit_bureau_b_2 = pl.read_csv(\"test/test_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef64ce350d4c7fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:46:59.302126Z",
     "start_time": "2024-04-08T21:46:58.930182Z"
    }
   },
   "outputs": [],
   "source": [
    "# We need to use aggregation functions in tables with depth > 1, so tables that contain num_group1 column or \n",
    "# also num_group2 column.\n",
    "train_person_1_feats_1 = train_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")\n",
    "\n",
    "# Here num_group1=0 has special meaning, it is the person who applied for the loan.\n",
    "train_person_1_feats_2 = train_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n",
    "\n",
    "# Here we have num_goup1 and num_group2, so we need to aggregate again.\n",
    "train_credit_bureau_b_2_feats = train_credit_bureau_b_2.group_by(\"case_id\").agg(\n",
    "    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n",
    "    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",
    ")\n",
    "\n",
    "# # We will process in this examples only A-type and M-type columns, so we need to select them.\n",
    "# selected_static_cols = []\n",
    "# for col in train_static.columns:\n",
    "#     if col[-1] in (\"A\", \"M\"):\n",
    "#         selected_static_cols.append(col)\n",
    "# print(selected_static_cols)\n",
    "\n",
    "# selected_static_cb_cols = []\n",
    "# for col in train_static_cb.columns:\n",
    "#     if col[-1] in (\"A\", \"M\"):\n",
    "#         selected_static_cb_cols.append(col)\n",
    "# print(selected_static_cb_cols)\n",
    "\n",
    "# # Join all tables together.\n",
    "# data = train_basetable.join(\n",
    "#     train_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    "# ).join(\n",
    "#     train_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    "# ).join(\n",
    "#     train_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    "# ).join(\n",
    "#     train_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    "# ).join(\n",
    "#     train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    "# )\n",
    "\n",
    "selected_static_cols = [col for col in train_static.columns if col != 'case_id']\n",
    "selected_static_cb_cols = [col for col in train_static_cb.columns if col != 'case_id']\n",
    "\n",
    "data = train_basetable.join(\n",
    "    train_static.select([\"case_id\"] + selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_static_cb.select([\"case_id\"] + selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46765b2280ad9010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:46:59.307368Z",
     "start_time": "2024-04-08T21:46:59.302743Z"
    }
   },
   "outputs": [],
   "source": [
    "test_person_1_feats_1 = test_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")\n",
    "\n",
    "test_person_1_feats_2 = test_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n",
    "\n",
    "test_credit_bureau_b_2_feats = test_credit_bureau_b_2.group_by(\"case_id\").agg(\n",
    "    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n",
    "    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",
    ")\n",
    "\n",
    "data_submission = test_basetable.join(\n",
    "    test_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "319f2edbafc735cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:47:00.942852Z",
     "start_time": "2024-04-08T21:46:59.307845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actualdpdtolerance_344P', 'amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_629L', 'applicationscnt_867L', 'avgdbddpdlast24m_3658932P', 'avgdbddpdlast3m_4187120P', 'avgdbdtollast24m_4525197P', 'avgdpdtolclosure24_3658938P', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgmaxdpdlast9m_3716943P', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'bankacctype_710L', 'cardtype_51L', 'clientscnt12m_3712952L', 'clientscnt3m_3712950L', 'clientscnt6m_3712949L', 'clientscnt_100L', 'clientscnt_1022L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_136L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'cntincpaycont9m_3716944L', 'cntpmts24_3658933L', 'commnoinclast6m_3546845L', 'credamount_770A', 'credtype_322L', 'currdebt_22A', 'currdebtcredtyperange_828A', 'datefirstoffer_1144D', 'datelastinstal40dpd_247D', 'datelastunpaid_3546854D', 'daysoverduetolerancedd_3976961L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'disbursementtype_67L', 'downpmt_116A', 'dtlastpmtallstes_4499206D', 'eir_270L', 'equalitydataagreement_891L', 'equalityempfrom_62L', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'homephncnt_628L', 'inittransactionamount_650A', 'inittransactioncode_186L', 'interestrate_311L', 'interestrategrace_34L', 'isbidproduct_1095L', 'isbidproductrequest_292L', 'isdebitcard_729L', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastapprdate_640D', 'lastcancelreason_561M', 'lastdelinqdate_224D', 'lastdependentsnum_448L', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectdate_50D', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'lastrepayingdate_696D', 'lastst_736L', 'maininc_215A', 'mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdbddpdlast1m_3658939P', 'maxdbddpdtollast12m_3658940P', 'maxdbddpdtollast6m_4187119P', 'maxdebt4_972A', 'maxdpdfrom6mto36m_3546853P', 'maxdpdinstldate_3546855D', 'maxdpdinstlnum_3546846P', 'maxdpdlast12m_727P', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdlast6m_474P', 'maxdpdlast9m_1059P', 'maxdpdtolerance_374P', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'mindbddpdlast24m_3658935P', 'mindbdtollast24m_4525191P', 'mobilephncnt_593L', 'monthsannuity_845L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numincomingpmts_3546848L', 'numinstlallpaidearly3d_817L', 'numinstls_657L', 'numinstlsallpaid_934L', 'numinstlswithdpd10_728L', 'numinstlswithdpd5_4187116L', 'numinstlswithoutdpd_562L', 'numinstmatpaidtearly2d_4499204L', 'numinstpaid_4499208L', 'numinstpaidearly3d_3546850L', 'numinstpaidearly3dest_4493216L', 'numinstpaidearly5d_1087L', 'numinstpaidearly5dest_4493211L', 'numinstpaidearly5dobd_4499205L', 'numinstpaidearly_338L', 'numinstpaidearlyest_4493214L', 'numinstpaidlastcontr_4325080L', 'numinstpaidlate1d_3546852L', 'numinstregularpaid_973L', 'numinstregularpaidest_4493210L', 'numinsttopaygr_769L', 'numinsttopaygrest_4493213L', 'numinstunpaidmax_3546851L', 'numinstunpaidmaxest_4493212L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'opencred_647L', 'paytype1st_925L', 'paytype_783L', 'payvacationpostpone_4187118D', 'pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlat10d_839L', 'pctinstlsallpaidlate1d_3546856L', 'pctinstlsallpaidlate4d_3546849L', 'pctinstlsallpaidlate6d_3546844L', 'pmtnum_254L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'previouscontdistrict_112M', 'price_1097A', 'sellerplacecnt_915L', 'sellerplacescnt_216L', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A', 'twobodfilling_608L', 'typesuite_864L', 'validfrom_1069D', 'assignmentdate_238D', 'assignmentdate_4527235D', 'assignmentdate_4955616D', 'birthdate_574D', 'contractssum_5085716L', 'dateofbirth_337D', 'dateofbirth_342D', 'days120_123L', 'days180_256L', 'days30_165L', 'days360_512L', 'days90_310L', 'description_5085714M', 'education_1103M', 'education_88M', 'firstquarter_103L', 'for3years_128L', 'for3years_504L', 'for3years_584L', 'formonth_118L', 'formonth_206L', 'formonth_535L', 'forquarter_1017L', 'forquarter_462L', 'forquarter_634L', 'fortoday_1092L', 'forweek_1077L', 'forweek_528L', 'forweek_601L', 'foryear_618L', 'foryear_818L', 'foryear_850L', 'fourthquarter_440L', 'maritalst_385M', 'maritalst_893M', 'numberofqueries_373L', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtcount_4527229L', 'pmtcount_4955617L', 'pmtcount_693L', 'pmtscount_423L', 'pmtssum_45A', 'requesttype_4525192L', 'responsedate_1012D', 'responsedate_4527233D', 'responsedate_4917613D', 'riskassesment_302T', 'riskassesment_940T', 'secondquarter_766L', 'thirdquarter_1082L']\n"
     ]
    }
   ],
   "source": [
    "case_ids = data[\"case_id\"].unique().shuffle(seed=1)\n",
    "case_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\n",
    "case_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\n",
    "\n",
    "cols_pred = []\n",
    "for col in data.columns:\n",
    "    if col[-1].isupper() and col[:-1].islower():\n",
    "        cols_pred.append(col)\n",
    "\n",
    "print(cols_pred)\n",
    "\n",
    "def from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n",
    "    return (\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[cols_pred].to_pandas(),\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[\"target\"].to_pandas()\n",
    "    )\n",
    "\n",
    "base_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\n",
    "base_valid, X_valid, y_valid = from_polars_to_pandas(case_ids_valid)\n",
    "base_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n",
    "\n",
    "for df in [X_train, X_valid, X_test]:\n",
    "    df = convert_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fba15a6f262f6cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:47:00.945350Z",
     "start_time": "2024-04-08T21:47:00.943577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (915995, 219)\n",
      "Valid: (305332, 219)\n",
      "Test: (305332, 219)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Valid: {X_valid.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af899c0e8ddeeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:47:14.666485Z",
     "start_time": "2024-04-08T21:47:00.945859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iswzh\\anaconda3\\envs\\cs567proj\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's auc: 0.772107\n",
      "[100]\tvalid_0's auc: 0.788719\n",
      "[150]\tvalid_0's auc: 0.795784\n",
      "[200]\tvalid_0's auc: 0.799792\n",
      "[250]\tvalid_0's auc: 0.802754\n",
      "[300]\tvalid_0's auc: 0.804629\n",
      "[350]\tvalid_0's auc: 0.806144\n",
      "[400]\tvalid_0's auc: 0.807258\n",
      "[450]\tvalid_0's auc: 0.808129\n",
      "[500]\tvalid_0's auc: 0.809039\n",
      "[550]\tvalid_0's auc: 0.809982\n",
      "[600]\tvalid_0's auc: 0.810826\n",
      "[650]\tvalid_0's auc: 0.811336\n",
      "[700]\tvalid_0's auc: 0.812177\n",
      "[750]\tvalid_0's auc: 0.81253\n",
      "[800]\tvalid_0's auc: 0.813143\n",
      "[850]\tvalid_0's auc: 0.813426\n",
      "[900]\tvalid_0's auc: 0.813762\n",
      "[950]\tvalid_0's auc: 0.813971\n",
      "Early stopping, best iteration is:\n",
      "[985]\tvalid_0's auc: 0.814199\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, label=y_valid, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 3,\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "model_gbm = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=lgb_valid,\n",
    "    callbacks=[lgb.log_evaluation(50), lgb.early_stopping(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fb267d67893d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:49:35.623169Z",
     "start_time": "2024-04-08T21:47:14.667443Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 对类别特征进行独热编码\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_valid_encoded = pd.get_dummies(X_valid)\n",
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "\n",
    "\n",
    "# 确保所有数据集具有相同的列\n",
    "X_train_encoded, X_valid_encoded = X_train_encoded.align(X_valid_encoded, join='outer', axis=1)\n",
    "X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='outer', axis=1)\n",
    "X_valid_encoded, X_test_encoded = X_valid_encoded.align(X_test_encoded, join='outer', axis=1)\n",
    "\n",
    "# 用 0 填充 NaN 值\n",
    "X_train_encoded = X_train_encoded.fillna(0)\n",
    "X_valid_encoded = X_valid_encoded.fillna(0)\n",
    "X_test_encoded = X_test_encoded.fillna(0)\n",
    "\n",
    "\n",
    "# 创建 XGBoost 模型实例\n",
    "model_XGBoost = XGBClassifier(objective='binary:logistic', n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "model_XGBoost.fit(X_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42e79c7e257801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:50:18.632283Z",
     "start_time": "2024-04-08T21:49:35.624408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 训练随机森林模型\n",
    "model_random_forest = RandomForestClassifier(n_estimators=1000, max_depth=3, random_state=42, n_jobs=-1)\n",
    "model_random_forest.fit(X_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebce9760998ae33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:50:27.983955Z",
     "start_time": "2024-04-08T21:50:18.632925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iswzh\\anaconda3\\envs\\cs567proj\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.58132e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 训练岭回归模型\n",
    "model_ridge = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "model_ridge.fit(X_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd752a6aa3b0b650",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T22:05:06.629331Z",
     "start_time": "2024-04-08T22:03:50.302153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score on the train set is: 0.7639849865945045\n",
      "The AUC score on the valid set is: 0.7553796054166325\n",
      "The AUC score on the test set is: 0.7484253338300456\n"
     ]
    }
   ],
   "source": [
    "# Create a function to generate meta-features\n",
    "def generate_meta_features(model, X_encoded, X):\n",
    "    y_pred_proba = model.predict_proba(X_encoded)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_encoded)\n",
    "    return y_pred_proba\n",
    "\n",
    "# Generate meta-features for the train, valid, and test sets\n",
    "meta_features_train = np.column_stack([\n",
    "    generate_meta_features(model_random_forest, X_train_encoded, X_train),\n",
    "    generate_meta_features(model_ridge, X_train_encoded, X_train),\n",
    "    generate_meta_features(model_XGBoost, X_train_encoded, X_train),\n",
    "    model_gbm.predict(X_train, num_iteration=model_gbm.best_iteration)\n",
    "])\n",
    "\n",
    "meta_features_valid = np.column_stack([\n",
    "    generate_meta_features(model_random_forest, X_valid_encoded, X_valid),\n",
    "    generate_meta_features(model_ridge, X_valid_encoded, X_valid),\n",
    "    generate_meta_features(model_XGBoost, X_valid_encoded, X_valid),\n",
    "    model_gbm.predict(X_valid, num_iteration=model_gbm.best_iteration)\n",
    "])\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # For regression\n",
    "\n",
    "meta_model = GradientBoostingRegressor()  # or GradientBoostingClassifier() for classification\n",
    "\n",
    "meta_model.fit(meta_features_valid, base_valid[\"target\"])\n",
    "\n",
    "# Generate meta-features for the test set and make final predictions\n",
    "meta_features_test = np.column_stack([\n",
    "    generate_meta_features(model_random_forest, X_test_encoded, X_test),\n",
    "    generate_meta_features(model_ridge, X_test_encoded, X_test),\n",
    "    generate_meta_features(model_XGBoost, X_test_encoded, X_test),\n",
    "    model_gbm.predict(X_test, num_iteration=model_gbm.best_iteration)\n",
    "])\n",
    "\n",
    "# Generate meta-features for the train set and make final predictions\n",
    "final_predictions_train = meta_model.predict(meta_features_train)\n",
    "base_train[\"score\"] = final_predictions_train\n",
    "\n",
    "# Generate meta-features for the valid set and make final predictions\n",
    "final_predictions_valid = meta_model.predict(meta_features_valid)\n",
    "base_valid[\"score\"] = final_predictions_valid\n",
    "\n",
    "# Generate meta-features for the test set and make final predictions\n",
    "final_predictions_test = meta_model.predict(meta_features_test)\n",
    "base_test[\"score\"] = final_predictions_test\n",
    "# Calculate AUC scores\n",
    "print(f'The AUC score on the train set is: {roc_auc_score(base_train[\"target\"], meta_model.predict(meta_features_train))}') \n",
    "print(f'The AUC score on the valid set is: {roc_auc_score(base_valid[\"target\"], meta_model.predict(meta_features_valid))}') \n",
    "print(f'The AUC score on the test set is: {roc_auc_score(base_test[\"target\"], base_test[\"score\"])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc4f5e78904858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T22:05:21.954927Z",
     "start_time": "2024-04-08T22:05:21.647935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stability score on the train set is: 0.4971429154444473\n",
      "The stability score on the valid set is: 0.48075094467694374\n",
      "The stability score on the test set is: 0.4590132528157713\n"
     ]
    }
   ],
   "source": [
    "def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n",
    "    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n",
    "        .sort_values(\"WEEK_NUM\")\\\n",
    "        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n",
    "        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n",
    "    \n",
    "    x = np.arange(len(gini_in_time))\n",
    "    y = gini_in_time\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_hat = a*x + b\n",
    "    residuals = y - y_hat\n",
    "    res_std = np.std(residuals)\n",
    "    avg_gini = np.mean(gini_in_time)\n",
    "    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\n",
    "\n",
    "stability_score_train = gini_stability(base_train)\n",
    "stability_score_valid = gini_stability(base_valid)\n",
    "stability_score_test = gini_stability(base_test)\n",
    "\n",
    "print(f'The stability score on the train set is: {stability_score_train}') \n",
    "print(f'The stability score on the valid set is: {stability_score_valid}') \n",
    "print(f'The stability score on the test set is: {stability_score_test}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e448ce1ed80ecf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T22:05:37.013874Z",
     "start_time": "2024-04-08T22:05:36.934337Z"
    }
   },
   "outputs": [],
   "source": [
    "X_submission = data_submission[cols_pred].to_pandas()\n",
    "X_submission = convert_strings(X_submission)\n",
    "categorical_cols = X_train.select_dtypes(include=['category']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_categories = set(X_train[col].cat.categories)\n",
    "    submission_categories = set(X_submission[col].cat.categories)\n",
    "    new_categories = submission_categories - train_categories\n",
    "    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n",
    "    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n",
    "    X_train[col] = X_train[col].astype(new_dtype)\n",
    "    X_submission[col] = X_submission[col].astype(new_dtype)\n",
    "\n",
    "# 对类别特征进行独热编码\n",
    "X_submission_encoded = pd.get_dummies(X_submission)\n",
    "# 确保特征对齐\n",
    "X_submission_encoded = X_submission_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "# 用 0 填充 NaN 值\n",
    "X_submission_encoded = X_submission_encoded.fillna(0)\n",
    "\n",
    "# Generate meta-features for the submission data\n",
    "meta_features_submission = np.column_stack([\n",
    "    model_random_forest.predict_proba(X_submission_encoded)[:, 1],\n",
    "    model_ridge.predict(X_submission_encoded),\n",
    "    model_XGBoost.predict_proba(X_submission_encoded)[:, 1],\n",
    "    model_gbm.predict(X_submission)\n",
    "])\n",
    "\n",
    "# Use the meta-model to make final predictions on the submission data\n",
    "y_submission_pred = meta_model.predict(meta_features_submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53d0fb357e3ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T22:05:40.468926Z",
     "start_time": "2024-04-08T22:05:40.463643Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"case_id\": data_submission[\"case_id\"].to_numpy(),\n",
    "    \"score\": y_submission_pred\n",
    "}).set_index('case_id')\n",
    "submission.to_csv(\"./submission_stacking_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix frequency in misclassified samples: {'M': 1}\n"
     ]
    }
   ],
   "source": [
    "# 假设已有的代码中，base_test, X_test, y_test, meta_model 已经准备好\n",
    "# 进行模型的预测\n",
    "y_pred = meta_model.predict(meta_features_test)\n",
    "\n",
    "# 将预测结果添加到base_test数据框中\n",
    "base_test[\"predicted\"] = y_pred\n",
    "\n",
    "# 找出错误的预测\n",
    "errors = base_test[base_test[\"predicted\"] != base_test[\"target\"]]\n",
    "\n",
    "# 分析错误预测中每个特征名称的字母后缀的出现频率\n",
    "def analyze_suffixes(df):\n",
    "    suffix_count = {}\n",
    "    for col in df.columns:\n",
    "        # 只关心原始特征，忽略其他添加的列如 'case_id', 'predicted', 'target'\n",
    "        if col not in ['case_id', 'predicted', 'target', 'score']:\n",
    "            suffix = col[-1]\n",
    "            if suffix in suffix_count:\n",
    "                suffix_count[suffix] += 1\n",
    "            else:\n",
    "                suffix_count[suffix] = 1\n",
    "    return suffix_count\n",
    "\n",
    "# 调用函数并打印结果\n",
    "suffix_frequency = analyze_suffixes(errors)\n",
    "print(\"Suffix frequency in misclassified samples:\", suffix_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3419c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All suffixes in the feature set: {'A', 'M'}\n"
     ]
    }
   ],
   "source": [
    "# 打印出所有使用的特征的后缀，以检查是否都被正确处理\n",
    "all_suffixes = {col[-1] for col in X_test.columns if col not in ['case_id', 'predicted', 'target', 'score']}\n",
    "print(\"All suffixes in the feature set:\", all_suffixes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
